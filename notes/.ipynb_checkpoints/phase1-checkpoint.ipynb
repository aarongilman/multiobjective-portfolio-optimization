{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data on environmental, social, and corporate(ESG)- sustainability rankings\n",
    "\n",
    "### 1.1 Finding and gathering data\n",
    "\n",
    "I found three sets of rankings on companies based on ESG factors:\n",
    "\n",
    "1. **Robecosam** ranks companies by ESG-scores, from 0 to 100. https://yearbook.robecosam.com/ranking/\n",
    "\n",
    "2. **Clean200** ranks companies by their solutions for transition to clean energy future. No scores, company either is on the list or not. https://www.asyousow.org/report-page/2020-clean200\n",
    "\n",
    "3. **ScienceBasedTargets** ranks companies by their science-based climate actions. No scores, company either is on the list or not. https://sciencebasedtargets.org/companies-taking-action/\n",
    "\n",
    "\n",
    "Datasets 2 and 3 were available and free to download as xlsx-files. Set 1 was not, so I wrote a web scraper- script. After that I converted all the three into csv-files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Examining and processing data\n",
    "\n",
    "As I had examined the rankings before, I knew that there is some companies on either all of the three ranking lists or then on two out of three. My plan was to combine information on these three datasets into a single one. This way, I could find companies that are ranked high on ESG performance.\n",
    "\n",
    "I chose the Robecosam's ranking(1) as \"base\" dataset, since it has the most companies, ~3200. For each of these companies, would go through the dataset 2 and 3 and if the name of the company is found on these rankings, mark 1 for that one. Otherwise, mark 0.\n",
    "\n",
    "On sets 1 and 2, the spelling on company names was identical, and thus it was easy to perform the matching search. However, on set 3 the spellings differed and thus the names could not be compared straight away (e.g. Fujitsu Limited & Fujitsu Ltd).\n",
    "\n",
    "So, I wrote an algorithm to \n",
    "1. check the matching words in two company names, \n",
    "2. exlude the acronyms (such as ltd, inc, co) from the matches, \n",
    "3. using a threshold value, determine if the amount of matching words is high enough for the two names to be considered equal.\n",
    "\n",
    "After this, I went through the dataset 1, and searched for the company names from sets 2 and 3. On dataset 3, there was also company country information available, so I also took that out. I stored these pieces of information into lists and finally combined them into the \"base\" dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data on historical market returns\n",
    "\n",
    "### 2.1 Finding and gathering data\n",
    "\n",
    "For calculating expected return on stock, one of the most common ways is to use Capital Asset Pricing Model (CAPM).\n",
    "\n",
    "For this, you should have knowledge of **market risk premium**, which is \n",
    "\n",
    "$\\text{average market return} - \\text{risk free rate}.$\n",
    "\n",
    "As risk free rate, for example return on 10-year government bonds are often used.\n",
    "\n",
    "For US stock market, S&P500 average market return is a good estimation. So, I downloaded historical(1928-2019) monthly data from Yahoo Finance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Examining and processing data\n",
    "\n",
    "The data was monthly, however for CAPM I want to use annual data. So, using the January's open values and next year's January's close values, I calculated the change in value for each year. The result, ~9.1% was in line with previous results. (https://www.investopedia.com/ask/answers/042415/what-average-annual-return-sp-500.asp, https://finance.yahoo.com/news/p-500-average-annual-return-231601665.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
